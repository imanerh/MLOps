{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c2ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faff6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89cb7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (53940, 11)\n",
      "\n",
      "First few rows:\n",
      "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
      "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
      "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
      "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
      "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
      "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
      "\n",
      "      z  \n",
      "0  2.43  \n",
      "1  2.31  \n",
      "2  2.31  \n",
      "3  2.63  \n",
      "4  2.75  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  53940 non-null  int64  \n",
      " 1   carat       53940 non-null  float64\n",
      " 2   cut         53940 non-null  object \n",
      " 3   color       53940 non-null  object \n",
      " 4   clarity     53940 non-null  object \n",
      " 5   depth       53940 non-null  float64\n",
      " 6   table       53940 non-null  float64\n",
      " 7   price       53940 non-null  int64  \n",
      " 8   x           53940 non-null  float64\n",
      " 9   y           53940 non-null  float64\n",
      " 10  z           53940 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 4.5+ MB\n",
      "None\n",
      "\n",
      "Statistical summary:\n",
      "         Unnamed: 0         carat         depth         table         price  \\\n",
      "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
      "mean   26970.500000      0.797940     61.749405     57.457184   3932.799722   \n",
      "std    15571.281097      0.474011      1.432621      2.234491   3989.439738   \n",
      "min        1.000000      0.200000     43.000000     43.000000    326.000000   \n",
      "25%    13485.750000      0.400000     61.000000     56.000000    950.000000   \n",
      "50%    26970.500000      0.700000     61.800000     57.000000   2401.000000   \n",
      "75%    40455.250000      1.040000     62.500000     59.000000   5324.250000   \n",
      "max    53940.000000      5.010000     79.000000     95.000000  18823.000000   \n",
      "\n",
      "                  x             y             z  \n",
      "count  53940.000000  53940.000000  53940.000000  \n",
      "mean       5.731157      5.734526      3.538734  \n",
      "std        1.121761      1.142135      0.705699  \n",
      "min        0.000000      0.000000      0.000000  \n",
      "25%        4.710000      4.720000      2.910000  \n",
      "50%        5.700000      5.710000      3.530000  \n",
      "75%        6.540000      6.540000      4.040000  \n",
      "max       10.740000     58.900000     31.800000  \n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(\"\\nStatistical summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cf15174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "Unnamed: 0    0\n",
      "carat         0\n",
      "cut           0\n",
      "color         0\n",
      "clarity       0\n",
      "depth         0\n",
      "table         0\n",
      "price         0\n",
      "x             0\n",
      "y             0\n",
      "z             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a380ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the index column if it exists\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712fc2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features for prediction\n",
    "# Features: carat, cut, color, clarity, depth, table, x, y, z\n",
    "# Target: price\n",
    "selected_features = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z', 'price']\n",
    "diamond_data = df[selected_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1af5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values or invalid entries\n",
    "# Replace any '?' with NaN\n",
    "col_names = diamond_data.columns\n",
    "for c in col_names:\n",
    "    diamond_data[c] = diamond_data[c].replace(\"?\", np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00bb9418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after treatment:\n",
      "carat      0\n",
      "cut        0\n",
      "color      0\n",
      "clarity    0\n",
      "depth      0\n",
      "table      0\n",
      "x          0\n",
      "y          0\n",
      "z          0\n",
      "price      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with mode for categorical and median for numerical\n",
    "for col in diamond_data.columns:\n",
    "    if diamond_data[col].dtype == 'object':\n",
    "        diamond_data[col] = diamond_data[col].fillna(diamond_data[col].mode()[0])\n",
    "    else:\n",
    "        diamond_data[col] = diamond_data[col].fillna(diamond_data[col].median())\n",
    "\n",
    "print(\"\\nMissing values after treatment:\")\n",
    "print(diamond_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffedb9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding mappings:\n",
      "{'cut': {'Fair': 0, 'Good': 1, 'Ideal': 2, 'Premium': 3, 'Very Good': 4}, 'color': {'D': 0, 'E': 1, 'F': 2, 'G': 3, 'H': 4, 'I': 5, 'J': 6}, 'clarity': {'I1': 0, 'IF': 1, 'SI1': 2, 'SI2': 3, 'VS1': 4, 'VS2': 5, 'VVS1': 6, 'VVS2': 7}}\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "cat_col = ['cut', 'color', 'clarity']\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "mapping_dict = {}\n",
    "\n",
    "for col in cat_col:\n",
    "    diamond_data[col] = labelEncoder.fit_transform(diamond_data[col])\n",
    "    le_name_mapping = dict(zip(labelEncoder.classes_, \n",
    "                              labelEncoder.transform(labelEncoder.classes_)))\n",
    "    mapping_dict[col] = le_name_mapping\n",
    "\n",
    "print(\"\\nEncoding mappings:\")\n",
    "print(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b20a27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mapping dictionary for later use in Flask app\n",
    "with open('label_mappings.pkl', 'wb') as f:\n",
    "    pickle.dump(mapping_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7483dc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 37758\n",
      "Test set size: 16182\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = diamond_data.drop('price', axis=1)  # features\n",
    "y = diamond_data['price']  # target\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "437bd18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LINEAR REGRESSION\n",
      "==================================================\n",
      "Train R¬≤ score: 0.8845\n",
      "Test R¬≤ score: 0.8864\n",
      "RMSE: 1331.26\n",
      "MAE: 856.41\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Model 1: Linear Regression\n",
    "# ==========================================\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LINEAR REGRESSION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "LRregressor = LinearRegression()\n",
    "LRregressor.fit(X_train, y_train)\n",
    "\n",
    "# Calculate scores\n",
    "lr_train_score = LRregressor.score(X_train, y_train)\n",
    "lr_test_score = LRregressor.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train R¬≤ score: {lr_train_score:.4f}\")\n",
    "print(f\"Test R¬≤ score: {lr_test_score:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "ypred_LR = LRregressor.predict(X_test)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, ypred_LR))\n",
    "lr_mae = mean_absolute_error(y_test, ypred_LR)\n",
    "\n",
    "print(f\"RMSE: {lr_rmse:.2f}\")\n",
    "print(f\"MAE: {lr_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "723f66b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DECISION TREE REGRESSOR\n",
      "==================================================\n",
      "Train R¬≤ score: 0.9812\n",
      "Test R¬≤ score: 0.9736\n",
      "RMSE: 641.51\n",
      "MAE: 344.23\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Model 2: Decision Tree Regressor\n",
    "# ==========================================\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DECISION TREE REGRESSOR\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "DTregressor = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "DTregressor.fit(X_train, y_train)\n",
    "\n",
    "# Calculate scores\n",
    "dt_train_score = DTregressor.score(X_train, y_train)\n",
    "dt_test_score = DTregressor.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train R¬≤ score: {dt_train_score:.4f}\")\n",
    "print(f\"Test R¬≤ score: {dt_test_score:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "ypred_DTr = DTregressor.predict(X_test)\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test, ypred_DTr))\n",
    "dt_mae = mean_absolute_error(y_test, ypred_DTr)\n",
    "\n",
    "print(f\"RMSE: {dt_rmse:.2f}\")\n",
    "print(f\"MAE: {dt_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff3228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RANDOM FOREST REGRESSOR\n",
      "==================================================\n",
      "Train R¬≤ score: 0.9944\n",
      "Test R¬≤ score: 0.9814\n",
      "Number of features: 9\n",
      "Feature importances: [0.62565245 0.00120135 0.02848111 0.06547832 0.00258115 0.0019082\n",
      " 0.00642964 0.26327585 0.00499193]\n",
      "RMSE: 538.36\n",
      "MAE: 271.67\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Model 3: Random Forest Regressor\n",
    "# ==========================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RANDOM FOREST REGRESSOR\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "RFregressor = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "RFregressor.fit(X_train, y_train)\n",
    "\n",
    "# Calculate scores\n",
    "rf_train_score = RFregressor.score(X_train, y_train)\n",
    "rf_test_score = RFregressor.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train R¬≤ score: {rf_train_score:.4f}\")\n",
    "print(f\"Test R¬≤ score: {rf_test_score:.4f}\")\n",
    "print(f\"Number of features: {RFregressor.n_features_in_}\")\n",
    "print(f\"Feature importances: {RFregressor.feature_importances_}\")\n",
    "\n",
    "# Make predictions\n",
    "ypred_RFr = RFregressor.predict(X_test)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, ypred_RFr))\n",
    "rf_mae = mean_absolute_error(y_test, ypred_RFr)\n",
    "\n",
    "print(f\"RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"MAE: {rf_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2ce9020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GRADIENT BOOSTING REGRESSOR\n",
      "==================================================\n",
      "Train R¬≤ score: 0.9850\n",
      "Test R¬≤ score: 0.9810\n",
      "RMSE: 544.47\n",
      "MAE: 288.10\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Model 4: Gradient Boosting Regressor\n",
    "# ==========================================\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GRADIENT BOOSTING REGRESSOR\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "GBregressor = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "GBregressor.fit(X_train, y_train)\n",
    "\n",
    "# Calculate scores\n",
    "gb_train_score = GBregressor.score(X_train, y_train)\n",
    "gb_test_score = GBregressor.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train R¬≤ score: {gb_train_score:.4f}\")\n",
    "print(f\"Test R¬≤ score: {gb_test_score:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "ypred_GBr = GBregressor.predict(X_test)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, ypred_GBr))\n",
    "gb_mae = mean_absolute_error(y_test, ypred_GBr)\n",
    "\n",
    "print(f\"RMSE: {gb_rmse:.2f}\")\n",
    "print(f\"MAE: {gb_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e010aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SUPPORT VECTOR REGRESSOR\n",
      "==================================================\n",
      "Train R¬≤ score: 0.9508\n",
      "Test R¬≤ score: 0.9512\n",
      "RMSE: 872.14\n",
      "MAE: 427.80\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Model 5: Support Vector Regressor\n",
    "# ==========================================\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUPPORT VECTOR REGRESSOR\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "SVMregressor = SVR(kernel='rbf', C=1000, gamma=0.1)\n",
    "SVMregressor.fit(X_train, y_train)\n",
    "\n",
    "# Calculate scores\n",
    "svm_train_score = SVMregressor.score(X_train, y_train)\n",
    "svm_test_score = SVMregressor.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train R¬≤ score: {svm_train_score:.4f}\")\n",
    "print(f\"Test R¬≤ score: {svm_test_score:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "ypred_SVMr = SVMregressor.predict(X_test)\n",
    "svm_rmse = np.sqrt(mean_squared_error(y_test, ypred_SVMr))\n",
    "svm_mae = mean_absolute_error(y_test, ypred_SVMr)\n",
    "\n",
    "print(f\"RMSE: {svm_rmse:.2f}\")\n",
    "print(f\"MAE: {svm_mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a14af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "==================================================\n",
      "            Model  Train R¬≤  Test R¬≤        RMSE        MAE\n",
      "Linear Regression  0.884512 0.886364 1331.262679 856.408322\n",
      "    Decision Tree  0.981248 0.973613  641.505390 344.229692\n",
      "    Random Forest  0.994356 0.981416  538.360204 271.674813\n",
      "Gradient Boosting  0.984971 0.980992  544.466692 288.095801\n",
      "              SVM  0.950786 0.951229  872.142171 427.804797\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Model Comparison\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Decision Tree', 'Random Forest', \n",
    "              'Gradient Boosting', 'SVM'],\n",
    "    'Train R¬≤': [lr_train_score, dt_train_score, rf_train_score, \n",
    "                 gb_train_score, svm_train_score],\n",
    "    'Test R¬≤': [lr_test_score, dt_test_score, rf_test_score, \n",
    "                gb_test_score, svm_test_score],\n",
    "    'RMSE': [lr_rmse, dt_rmse, rf_rmse, gb_rmse, svm_rmse],\n",
    "    'MAE': [lr_mae, dt_mae, rf_mae, gb_mae, svm_mae]\n",
    "})\n",
    "\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0a0a6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Best Model: Random Forest\n",
      "   Test R¬≤: 0.9814\n",
      "   RMSE: 538.36\n"
     ]
    }
   ],
   "source": [
    "# Select the best model based on test R¬≤ score\n",
    "best_model_idx = comparison_df['Test R¬≤'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   Test R¬≤: {comparison_df.loc[best_model_idx, 'Test R¬≤']:.4f}\")\n",
    "print(f\"   RMSE: {comparison_df.loc[best_model_idx, 'RMSE']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f6c22e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Model saved as 'model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "models = {\n",
    "    'Linear Regression': LRregressor,\n",
    "    'Decision Tree': DTregressor,\n",
    "    'Random Forest': RFregressor,\n",
    "    'Gradient Boosting': GBregressor,\n",
    "    'SVM': SVMregressor\n",
    "}\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Save the best model\n",
    "pickle.dump(best_model, open('model.pkl', 'wb'))\n",
    "print(f\"\\n‚úì Model saved as 'model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3252797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test prediction (first 5 samples): [ 545.51279452 2414.97875036 1183.39392735 1243.05241328 9317.64827014]\n",
      "Actual values (first 5 samples): [ 559 2201 1238 1304 6901]\n"
     ]
    }
   ],
   "source": [
    "# Test loading the model\n",
    "model_loaded = pickle.load(open('model.pkl', 'rb'))\n",
    "test_prediction = model_loaded.predict(X_test[:5])\n",
    "print(f\"\\nTest prediction (first 5 samples): {test_prediction}\")\n",
    "print(f\"Actual values (first 5 samples): {y_test.iloc[:5].values}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
